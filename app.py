import streamlit as st
import yaml
import json
import os
from prompt_agent import PromptAgent

# Configura√ß√£o da p√°gina Streamlit
st.set_page_config(
    page_title="Agente de Engenharia de Prompt - Academia Lend√°ria",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Fun√ß√£o para carregar as configura√ß√µes
def load_config():
    if os.path.exists("config.yaml"):
        with open("config.yaml", 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    return {}

# Verifica se h√° uma chave API configurada
def is_api_key_configured():
    config = load_config()
    return bool(config.get('api_key', {}).get('key'))

# Inicializa√ß√£o da sess√£o
if 'conversation_started' not in st.session_state:
    st.session_state.conversation_started = False
    
if 'messages' not in st.session_state:
    st.session_state.messages = []
    
if 'agent' not in st.session_state:
    st.session_state.agent = None
    
if 'use_llm' not in st.session_state:
    # Por padr√£o, usa o LLM se a configura√ß√£o estiver dispon√≠vel
    st.session_state.use_llm = is_api_key_configured()

# Fun√ß√£o para inicializar ou reiniciar o agente
def initialize_agent():
    if st.session_state.agent:
        st.session_state.agent.close()
    
    st.session_state.agent = PromptAgent(use_llm=st.session_state.use_llm)
    st.session_state.conversation_started = True
    st.session_state.messages = []

# Sidebar com configura√ß√µes
with st.sidebar:
    st.title("Configura√ß√µes")
    
    # Op√ß√£o para alternar entre LLM e base local
    use_llm = st.checkbox("Usar LLM", value=st.session_state.use_llm)
    
    if use_llm != st.session_state.use_llm:
        st.session_state.use_llm = use_llm
        if st.session_state.conversation_started:
            initialize_agent()
    
    # Bot√µes de a√ß√£o
    if st.button("Limpar Conversa"):
        if st.session_state.agent:
            st.session_state.agent.clear_conversation()
        st.session_state.messages = []
    
    if st.button("Executar Testes"):
        if not st.session_state.agent:
            initialize_agent()
        
        with st.spinner("Executando testes..."):
            results = st.session_state.agent.validator.run_all_tests(st.session_state.agent)
            
        st.write("### Resultados dos Testes")
        st.write(results["message"])
        st.write(f"Taxa de Precis√£o: {results['accuracy_rate']:.1f}%")
        
        # Exibe detalhes dos testes
        with st.expander("Ver detalhes dos testes"):
            for i, test in enumerate(results["results"], 1):
                status = "‚úÖ" if test["is_valid"] else "‚ùå"
                st.write(f"{status} **Teste {i}:** {test['question']}")
                if not test["is_valid"]:
                    st.write(f"- Esperado: {test['expected_response'][:100]}...")
                    st.write(f"- Recebido: {test['actual_response'][:100]}...")
    
    # Exibe o status do LLM
    st.write("---")
    if st.session_state.use_llm:
        st.success("üì° Modo LLM ativo")
    else:
        st.info("üìö Usando base de conhecimento local")
    
    st.write("---")
    st.write("### Sobre")
    st.write("Agente de Engenharia de Prompt da Academia Lend√°ria")
    st.write("Vers√£o 1.0")

# T√≠tulo principal
st.title("ü§ñ Agente de Engenharia de Prompt")
st.write("Tire suas d√∫vidas sobre Engenharia de Prompt e melhores pr√°ticas")

# Inicializa o agente se necess√°rio
if not st.session_state.conversation_started:
    initialize_agent()

# Exibe o hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])
        
        # Se for uma mensagem do agente e tiver insights, mostra-os
        if message.get("insights") and message["role"] == "assistant":
            with st.expander("Ver insights"):
                st.json(message["insights"])

# Input para nova mensagem
if prompt := st.chat_input("Digite sua pergunta ou 'hist√≥rico' para ver conversas anteriores"):
    # Adiciona a mensagem do usu√°rio ao chat
    with st.chat_message("user"):
        st.write(prompt)
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Comandos especiais
    if prompt.lower() == 'hist√≥rico':
        # Obt√©m o hist√≥rico de conversas do banco de dados
        history = st.session_state.agent.get_conversation_history()
        
        with st.chat_message("assistant"):
            st.write("### Hist√≥rico de Conversas")
            for msg in history:
                role = "Usu√°rio" if msg["role"] == "user" else "Agente"
                st.write(f"**{role}** ({msg['timestamp']}): {msg['content']}")
                
        st.session_state.messages.append({
            "role": "assistant", 
            "content": "Hist√≥rico de conversas exibido acima."
        })
    else:
        # Processa a pergunta normal
        with st.spinner("Pensando..."):
            response, found = st.session_state.agent.get_response(prompt)
            
            # Obt√©m insights da √∫ltima intera√ß√£o
            last_interaction = st.session_state.agent.get_structured_output()
            insights = {}
            if last_interaction.get("recent_interactions"):
                insights = last_interaction["recent_interactions"][0].get("insights", {})
        
        # Exibe a resposta
        with st.chat_message("assistant"):
            st.write(response)
            
            # Exibe informa√ß√µes adicionais conforme dispon√≠vel
            if not st.session_state.use_llm and found:
                st.info("Informa√ß√£o encontrada na base de conhecimento local")
            
        # Adiciona a resposta do assistente ao hist√≥rico da sess√£o
        st.session_state.messages.append({
            "role": "assistant", 
            "content": response,
            "insights": insights
        })

# Rodap√©
st.write("---")
st.write("Digite suas perguntas sobre Engenharia de Prompt no campo acima.")
st.write("Use 'hist√≥rico' para ver conversas anteriores armazenadas no banco de dados.") 